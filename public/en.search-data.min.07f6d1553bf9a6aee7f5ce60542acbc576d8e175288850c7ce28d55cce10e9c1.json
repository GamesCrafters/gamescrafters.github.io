[{"id":0,"href":"/main/about/course/","title":"About the Course","section":"Information","content":" Course Details # Warning: This page is under construction.\n"},{"id":1,"href":"/main/links/github/","title":"GitHub Organization","section":"Links","content":"\n"},{"id":2,"href":"/archive/puzzle-homefun/","title":"Homefun","section":"Archives","content":" Homefun # Due: February 3, 2025\nWarning: This page is under construction.\nLogistics This assignment is managed through a single Github classroom assignment. You can accept it via this link. This will create a new repository that you have write access to. Once you accept it, read the README file.\nWhen you push commits to this repository, an automatic testing job will run pre-written tests. These tests verify that your program produces the right outputs on certain inputs. You can find verbal descriptions of each one in the \u0026ldquo;Checks\u0026rdquo; section. Further, all of the tests\u0026rsquo; expected input/output pairs are publically visible in the autograder workflow runs.\nIf the latest commit on your Homefun repository\u0026rsquo;s main branch passes all tests before the due date passes, you will receive full credit. If you do not pass the necessary autograder tests before the due date passes, your work can be reviewed by an organizer on an effort basis upon request (so you should always let someone know if you won\u0026rsquo;t finish in time).\nSummary # Write a program that encodes two puzzles generically and uses this encoding to compute \u0026ldquo;perfect solutions\u0026rdquo; for them. Any programming language is acceptable. Optional aid is provided in the form of a Python template.\nExplanation # Here, we give a bare-minimum introduction to essential concepts you will encounter while you complete this assignment. We highly recommend you read through the appended theoretic introduction for motivation and context, as well as the other provided resources.\nPuzzles and Games # Puzzles are games in both a formal and informal sense; we play them to have fun, and in formal theory they are the single-player subclass of games. As such, we will introduce concepts that are applicable for games in general, even if we will only explore them in-depth for puzzles.\nPuzzles and Rulesets # The puzzles we are interested in are determined by what positions they can find themselves in, what players there are, how positions can transition to others, and by what positions are terminal (and the benefit associated with reaching them according to each player).\nWhen we talk about puzzles colloquially, we don\u0026rsquo;t usually refer to all of these things. If someone refers to the game of Chess, they are not referring to it in terms of its positions, but rather in terms of the ruleset that \u0026ldquo;generates\u0026rdquo; the game itself. In doing so, they can communicate a game with $\u0026gt;10^{100}$ unique positions in only about a page of rules.\nThe process of encoding a ruleset in a computer and obtaining a subset of positions in the puzzle it generates (perhaps figuring out interesting facts about it in the process) is known as \u0026ldquo;exploration\u0026rdquo; or \u0026ldquo;search.\u0026rdquo; This is what we will do in this Homefun.\nOur First Ruleset # The wolf, goat, and cabbage problem is a very old logic puzzle, defined as follows:\nA farmer with a wolf, a goat, and a cabbage wants to cross a river by boat. The boat can carry only the farmer and a single item per trip across the river. If left alone together, the goat would eat the cabbage. If left alone together, the wolf would eat the goat. It is quite a simple puzzle. Try figuring out a perfect strategy for it by hand or in your head. We will explore how you can have a computer do this. But as a first step, we will show how we might be able to represent this in code below.\nThe Puzzle Interface # All of the rulesets we are interested in have very clear conditions for success and failure, and they describe what the player (e.g., the farmer) can do. We can leverage this to write an interface for puzzles that we can later write generic code for.\ninterface Puzzle: function start() -\u0026gt; Position function get_moves(Position) -\u0026gt; Collection\u0026lt;Move\u0026gt; function do_move(Position, Move) -\u0026gt; Position So now, if we wished to write code that could explore a puzzle for us, it could be defined generically with this interface. And later, the only work we would need to do is fill out the functions of this interface according to the ruleset we are interested in.\nFamilies of Puzzles # The missionaries and cannibals problem is a very similar logic puzzle, where:\nA bishop with three missionaries and three cannibals wants to cross a river by boat. Only the bishop can row the boat, which can carry at most two additional people. The boat needs at least one more person apart from the bishop to float with stability. If cannibals are around less missionaries, they would eat them (even if the bishop is around). The bishop cannot stop cannibals, but the cannibals do not want to eat the bishop. This puzzle is more complicated than the last, but you will notice that they have many things in common. In fact, they have so much in common that it might feel silly to re-implement the Puzzle interface for each one.\nThis situation happens a lot. Here, we call these puzzles variants of one another. In other words, they are under the same family of puzzles (in this case, river crossing puzzles). Sometimes puzzles in the same family are so logically similar that it is better to implement the Puzzle interface once for the whole family, and then provide a way to instantiate concrete puzzles via a constructor.\nProgrammers decide convenient levels of abstraction for families of puzzles and games according to what they want. For example, implementing Puzzle for the family of river crossing puzzles may necessitate the use of hashmaps, so a programmer might avoid doing so because of how slow they are to use. Conversely, implementing Puzzle for each of the concrete rulesets might result in a lot of repeated code, which is also bad.\nDeliverable # Write an exploration module that only knows about the Puzzle interface, and from its provided methods, can generate strong solutions to concrete puzzles.\nThen, encode both of the river crossing problems mentioned above as separate implementations of the Puzzle interface. Alternatively, make a single implementation of the Puzzle interface for a family of river crossing problems that includes both of these puzzles. The latter option should be challenging but fun.\nFinally, write code that allows your program to call the exploration module on an argument Puzzle implementation by name and print the generated strong solution to STDOUT.\nRegardless of your programming language and of whether you choose to create separate Puzzle implementations, your exploration module should not depend in any way on any information about either of the two rulesets (beyond the generic Puzzle interface).\nChecks # TODO\nResources # Here are some things that might help you get started.\nThe appendix below Dan\u0026rsquo;s CalWeek 2020 Lecture Dan\u0026rsquo;s Computational Game Theory Slides Rogue AI Riddle Appendix # We provide an introduction to games by comparing them to optimization problems, and explain what solution concepts and strong solutions are. Finally, we present puzzles as 1-player games.\nGames vs. Problems # A single-objective optimization problem attempts to maximize or minimize a value with respect to a set of parameters. For example, the optimization problem\n$$ \\max_{0 \\leq x \\leq 1} f(x) $$asks a very clear question: \u0026ldquo;Given $f : \\mathbb{R} \\to \\mathbb{R}$ and $x \\in [0, 1]$, what is the maximum possible value $f$ can take?\u0026rdquo; However, a game is a situation, not a problem. We will skip a proper definition, but the cornestone assumption is that each player attempts to maximize their own utility. But from a global perspective, there is no obvious \u0026ldquo;ask\u0026rdquo; when presented with a game (unlike optimization problems).\nIt is tempting to believe that there exists some \u0026ldquo;universally optimal\u0026rdquo; way of playing any game, and therefore a way of predicting how any game will be played. It turns out this is not true under most conditions. This is non-obvious, and took a lot of bright minds to figure out. However, for many specific kinds of games, there exist very reasonable rules that can be used to predict how a game will be played a priori.\nSolution Concepts # Each different way to formulate such rules is called a solution concept. A very famous solution concept is the Nash Equilibrium. It tells us to look at all of the possible strategies that players could implement, and look for groups of strategies (one per player) where no player could be better off by only changing their own strategy. This applies to games where players cannot cooperate. Each of these strategy \u0026ldquo;profiles\u0026rdquo; (a one-per-player set of strategies) is called a Nash Equilibrium.\nIn a very specific subset of games that are deterministic, complete-information, sequential, finite, and either non-cooperative or zero-sum (such as Chess), there is an efficient way of computing such strategy profiles known as backward induction, which refers to the procedure of analyzing players\u0026rsquo; choices \u0026ldquo;in reverse,\u0026rdquo; assuming everyone does what is best for them. In the specific subcase of zero-sum games, this is implemented by the popular Minmax algorithm.\nStrong Solutions # The game-theoretic value of a position is the highest utility that a player whose turn it is at that position can guarantee to obtain for themselves through their own actions. Oftentimes, the way in which we compute optimal strategies under different solution concepts is by storing a mapping of all positions in a game to their values. When we have such a mapping, we also have access to the best possible strategies in the corresponding game from any position.\nSuch a mapping is equivalent to something known as a strong solution, as it provides the answer to the question: \u0026ldquo;Given any position in the game, what is the best possible course of action?\u0026rdquo; It is not obvious why this is possible; to figure out the best possible action from a position, it suffices to look at the values of all possible positions that the player who is \u0026ldquo;in power\u0026rdquo; at that position could transform the game into, and materialize the one that is most utilitarian for that player.\nWhile the name may suggest so, a strong solution is not a solution concept. A solution concept is a convention of sorts, while a strong solution is actual data.\nGames to Puzzles # Removing the complexity of conflicting player interests makes single-player games more akin to single-objective optimization problems, as opposed to the complicated situations that their multi-player cousins are likened to.\nThis fact is constantly reflected in the systems you will be building on top of; sometimes they will be generic, using the same infrastructure for multi-player games and puzzles; other times, there will be dedicated platforms for puzzles, which allow builders to cut the corners that are only necessary when dealing with multi-player games.\nRegardless, all of the vocabulary that is used when talking about multi-player games (e.g., strong solutions) is still valid for puzzles because they are still games. In this assignment, everything you learn will also be at least partially applicable to multi-player games.\n"},{"id":3,"href":"/archive/game-homefun-p1/","title":"Homefun Pt. 1","section":"Archives","content":" Homefun Part 1 # Due: 11:59PM 9/11/2024\nLogistics Both parts of the Homefun are managed through a single Github classroom assignment. You can accept it here. This will create a new repository that you have write access to. Read the README. When you push new commits on this repository, an \u0026ldquo;autograding\u0026rdquo; job will run the tests for both parts.\nThese tests simply verify that your program has the correct outputs for certain inputs. Each part has a set of input/output pairs that the tests enforce. If the latest commit on your Homefun repository\u0026rsquo;s main branch passes all of a given part\u0026rsquo;s tests before its due date passes, you will receive full credit for that part of the Homefun. You can see which tests belong to which part in the assignments\u0026rsquo; \u0026ldquo;Checks\u0026rdquo; sections.\nThis means that you may not need to pass all \u0026ldquo;autograding\u0026rdquo; tests to complete a particular part (because they include the other part\u0026rsquo;s tests), but you should pass all tests once you complete both. All of the tests\u0026rsquo; expected input/output pairs are publically visible in the autograder workflow runs. If you do not pass the necessary autograder tests before a due date passes, your work will be reviewed by an organizer on an effort basis.\nSummary # Write a program that computes the strong solution of two related games, 10-to-0-by-1-or-2 and 25-to-0-by-1-3-or-4. Any programming language is acceptable. Optional aid is provided in the form of a Python template.\nGame Representation # The object of the Homefun series will be to find out specific facts about a certain class of games. It can be summarized as: \u0026ldquo;For games like Chess, Tic-Tac-Toe, and Connect-4, how do I put them into a computer and have it tell me how to play perfectly?\u0026rdquo;\nThis is enough to get an intuitive understanding of the activities, but we highly recommend you read through the appended theoretic introduction. Refer to it if you see an unknown term.\nGames and Rulesets # Having narrowed down the games we will be dealing with, we can provide a semi-formal definition of a game. Games in this subset are determined by what positions they can find themselves in, what players there are, how positions can transition to another, and by what positions are terminal (and what benefit is associated with reaching them).\nWhen we talk about games colloquially, we don\u0026rsquo;t usually refer to all of these things. If someone refers to Chess, they are not referring to it in terms of its positions, but rather in terms of the ruleset that \u0026ldquo;generates\u0026rdquo; the game itself. In doing so, they can communicate a game with $\u0026gt;10^{100}$ unique positions in only about a page of rules, which can be memorized.\nThe process of encoding a ruleset in a computer and obtaining a subset of positions in the game it generates (perhaps figuring out interesting facts about it in the process) is known as \u0026ldquo;exploration\u0026rdquo; or \u0026ldquo;search.\u0026rdquo; This is what we will do in this Homefun, for two specific rulesets.\nOur First Ruleset # The game 10-to-0-by-1-2 is generated by the following ruleset:\nThere is a collection of 10 items. 2 players take alternating turns removing either 1 or 2 items from the collection. Player 1 starts. The player who takes the last item from the collection wins. It is quite a simple game. Try playing it with someone else to become familiar with it. You can even try figuring out a perfect strategy for it by hand or in your head, but it is somewhat difficult. We will explore how you can have a computer do this. But before that, we will hint at how we might be able to take advantage of modern generic programming by introducing the idea of a game family.\nFamilies of Games # The zero-by family is the set of games achievable via the parameterization N-to-0-by-S, where N is a positive integer and S is a set of positive integers. The generic ruleset is as follows:\nThere is a collection of N items. 2 players take alternating turns removing an amount of items in the set S from the collection. Player 1 starts. The player who takes the last item from the collection wins. If we do not restrict S, it is possible to choose parameters for which a terminal position cannot be reached (e.g., 11-to-0-by-5). Hence, we will include a new rule in the generic version:\nIf a player can remove more items than there are left in the collection, they can remove all remaining items (winning the game in the process). It is also possible to parameterize this ruleset on player count; we decide how abstract we make a family\u0026rsquo;s parameterization. We motivate this decision by semantics and the available provisions for generic constructs in our programming language of choice.\nUltimately, a game family is the set of games describable by concretizing the parameters of its generic ruleset. The games within a game family are often referred to as \u0026ldquo;variants\u0026rdquo; of each other, and games which belong to obvious families are sometimes called \u0026ldquo;variable.\u0026rdquo;\nThe Game Interface # We will work with the following way of programmatically characterizing any ruleset:\ninterface Game: function start() -\u0026gt; Position function get_moves(Position) -\u0026gt; Collection\u0026lt;Move\u0026gt; function do_move(Position, Move) -\u0026gt; Position function terminal_value(Position) -\u0026gt; Value This is not a real programming language, but the idea of an interface is central to generic programming in most programming languages.\nThe start function provides a way to specify how a game starts. The get_moves function returns a collection of things you can do from a given position; do_move applies one of those things onto a position and returns the resulting position, assuming it is allowed. In the case of terminal positions, terminal_value specifies the benefit obtained by the player whose turn it is at that position.\nThis interface is very general, but it does assume a turn order (e.g., alternating play). Including a turn(Position) -\u0026gt; Player function fixes this. There are many other (perhaps more elegant) ways to present the Game interface, but we have found that this is an intuitive first impression.\nDeliverable # Implement the rulesets 10-to-0-by-1-or-2 and 25-to-0-by-1-3-or-4, write a single solving algorithm that computes the mappings of positions in each of these games to their values, and print the mappings in a specific format (shown in the next section).\nRemember that these two games are part of a very intuitive family; you should not need to repeat much logic, if any at all. Here are some steps we recommended you take to do this:\nRead through the Python template, making sure to read the README. Make a mental path of how inputs enter the program, and of how outputs are created. Take note of the TODO hints left throughout the template. Design tests that the functions you implement will need to pass. Implement your solution, and iterate using your tests. Remember that you can choose to delete all the files in the provided template and code your solution from scratch!\nResources # Here are some things that might help you get started:\nDan\u0026rsquo;s CalWeek 2020 Lecture Dan\u0026rsquo;s Computational Game Theory Slides Rogue AI Riddle Checks # The following commands will be ran from your submission\u0026rsquo;s top-level directory verbatim. We will expect to see the output shown below each of them in STDOUT. There will be no input provided through STDIN. If you are using the template, you should just need to write print statements.\n10-to-0-by-1-or-2 # Command:\nmake run ARGS=\u0026#34;zero_by 10 1 2\u0026#34; Expected output:\n10: WIN 9: LOSE 8: WIN 7: WIN 6: LOSE 5: WIN 4: WIN 3: LOSE 2: WIN 1: WIN 0: LOSE 25-to-0-by-1-3-or-4 # Command:\nmake run ARGS=\u0026#34;zero_by 25 1 3 4\u0026#34; Output not shown for brevity.\nAppendix # Games vs. Problems # An optimization problem attempts to maximize or minimize an objective with respect to a set of parameters. For example, the optimization problem\n$$ \\max_{0 \\leq x \\leq 1} f(x) $$asks a very clear question: \u0026ldquo;Given $f : \\mathbb{R} \\to \\mathbb{R}$ and $x \\in [0, 1]$, what is the maximum possible value $f$ can take?\u0026rdquo; However, a game is a situation, not a problem. While we will visit proper definitions later, the cornestone assumption is that each player attempts to maximize their own utility in these situations (whatever that may mean). But from a global perspective, there is no obvious \u0026ldquo;ask\u0026rdquo; when presented with a game (unlike optimization problems).\nIt is tempting to believe that there exists some \u0026ldquo;universally optimal\u0026rdquo; way of playing any game, and therefore a way of predicting how any game will be played. It turns out this is not true under most conditions. This is non-obvious, and took a lot of bright minds to figure out. However, for many specific kinds of games, there exist very reasonable rules that can be used to predict how a game will be played a priori.\nSolution Concepts # Each different way to formulate such rules is called a solution concept. A very famous solution concept is the Nash Equilibrium. It tells us to look at all of the possible strategies that players could implement, and look for groups of strategies (one per player) where no player could be better off by only changing their own strategy. This applies to games where players cannot cooperate. Each of these strategy \u0026ldquo;profiles\u0026rdquo; (a one-per-player set of strategies) is called a Nash Equilibrium.\nIn a very specific subset of games that are deterministic, complete-information, sequential, finite, and either non-cooperative or zero-sum (such as Chess), there is an efficient way of computing such strategy profiles known as backward induction, which refers to the procedure of analyzing players\u0026rsquo; choices \u0026ldquo;in reverse,\u0026rdquo; assuming everyone does what is best for them. In the specific subcase of zero-sum games, this is implemented by the popular Minmax algorithm. For the remainder of the Homefun series, we will only talk about this kind of game.\nStrong Solutions # The game-theoretic value of a position is the highest utility that a player whose turn it is at that position can guarantee to obtain for themselves through their own actions. Oftentimes, the way in which we compute optimal strategies under different solution concepts is by storing a mapping of all positions in a game to their values. When we have such a mapping, we also have access to the best possible strategies in the corresponding game from any position.\nSuch a mapping is equivalent to something known as a strong solution, as it provides the answer to the question: \u0026ldquo;Given any position in the game, what is the best possible course of action?\u0026rdquo; It is not obvious why this is possible; to figure out the best possible action from a position, it suffices to look at the values of all possible positions that the player who is \u0026ldquo;in power\u0026rdquo; at that position could transform the game into, and materialize the one that is most utilitarian for that player.\nRemember that this is only referring to the subset of games described above. For example, we can only talk about a player \u0026ldquo;in power\u0026rdquo; because we assume the game is sequential.\nWhile the name may suggest so, a strong solution is not a solution concept. A solution concept is a convention of sorts, while a strong solution is actual data.\n"},{"id":4,"href":"/archive/game-homefun-p2/","title":"Homefun Pt. 2","section":"Archives","content":" Homefun Part 2 # Due: 11:59PM 9/23/2024\nWarning: This part is missing test outputs. They will be added soon, but you can begin your implementation without them.\nLogistics Both parts of the Homefun are managed through a single Github classroom assignment. You can accept it here. This will create a new repository that you have write access to. Read the README. When you push new commits on this repository, an \u0026ldquo;autograding\u0026rdquo; job will run the tests for both parts.\nThese tests simply verify that your program has the correct outputs for certain inputs. Each part has a set of input/output pairs that the tests enforce. If the latest commit on your Homefun repository\u0026rsquo;s main branch passes all of a given part\u0026rsquo;s tests before its due date passes, you will receive full credit for that part of the Homefun. You can see which tests belong to which part in the assignments\u0026rsquo; \u0026ldquo;Checks\u0026rdquo; sections.\nThis means that you may not need to pass all \u0026ldquo;autograding\u0026rdquo; tests to complete a particular part (because they include the other part\u0026rsquo;s tests), but you should pass all tests once you complete both. All of the tests\u0026rsquo; expected input/output pairs are publically visible in the autograder workflow runs. If you do not pass the necessary autograder tests before a due date passes, your work will be reviewed by an organizer on an effort basis.\nSummary # Bolster the solver you wrote for Part 1 to handle 100-to-0-by-1-or-2. Implement the ruleset of Tic-Tac-Toe, and write a hash function and its inverse to allow the solving algorithm you wrote to interface with this new Game implementation.\nGame Abstraction # In Part 1, we provided a semi-formal definition of a game in terms of the positions it could find itself in. This heavily relied on intuition and put a lot of weight on the term \u0026ldquo;position.\u0026rdquo;\nIt turns out that the idea of a position is a conceptual add-on to games. That is, games do not \u0026ldquo;come with\u0026rdquo; positions; they are expressed entirely in terms of sequences of actions taken by players. Such a sequence of actions is called a \u0026ldquo;history.\u0026rdquo;\nIn this section, we will bridge the ideas of a \u0026ldquo;history\u0026rdquo; and a \u0026ldquo;position.\u0026rdquo; We will then observe that our existing understanding of a \u0026ldquo;position\u0026rdquo; is arbitrary. Finally, we will relax this preconceived notion into a class of techniques known as \u0026ldquo;game abstraction\u0026rdquo; that are useful when exploring \u0026ldquo;bigger\u0026rdquo; games.\nNote that we are still talking about a restricted subset of games, as explained in Part 1.\nNaive Solvers # In Part 1, you may have written a solving algorithm that looks somewhat like the following pseudocode in order to solve the zero_by family of games:\nfunction solve(position) if position is terminal return value of position else opponent = worst_value( solve(result of taking action from position) for action in possible actions from position ) return opposite_value(opponent) This essentially says that the value of a position is its terminal value (if it has one), or the opposite of the worst possible outcome that can be forced into the opponent\u0026rsquo;s hands (e.g., if we can force the opponent to lose then we can win). If we take a look at the call graph of this recursive function when applied to Tic-Tac-Toe, we may see something like this:\nFrom this, we can observe that the solve function is called once for each possible sequence of actions in the game. This tells us that by writing our solver this way we have effectively encoded the game by its set of histories $H$, and that the amount of time our solver will take to terminate will be proportional to $|H|$.\nPosition Semantics # Without preamble, a position $p \\in P$ is a symbol that represents its own preimage under some function $f : H \\to P$ (a function that takes a history and returns a symbol from a set $P$).\nWe will unpack this confusing definition by talking about a function $f$ that makes it intuitive. In casual conversation, we usually take $f(h)$ to be \u0026ldquo;the board resulting from the application of all of the actions in $h$ to the starting game board,\u0026rdquo; and $P$ to be the set of all possible physical board configurations. For example, using this interpretation of $f$ and $P$, we would come to the conclusion that we are calling solve twice on the same position in the previous example:\nWhy don\u0026rsquo;t we just say that positions are board states?\nNot all games have boards, and not all boards carry all of the information we care about in a game. For example, a board of Chess does not indicate whether the 50-move rule is active.\nAbstract Strategy Games # We did not go to the trouble of defining positions this way just out of fear of picking wrong game representations. This is kind of mistake is not silent \u0026ndash; when the time comes to use your symbols, you simply would not have the information you need.\nThe real reason we choose these mathematics is to \u0026ldquo;game\u0026rdquo; abstract strategy games. By involving these constructs, we can take advantage of the fact that their rulesets are expressed in terms of symbols to begin with (which is what gives them the \u0026ldquo;abstract\u0026rdquo; qualifier). Because they are expressed in terms of abstract symbols (such as game boards or mathematical objects like sets), their histories oftentimes exhibit the structure that the symbols themselves inherently carry.\nThis means quite a few things. To begin with, we can almost exclusively transact in symbols when analyzing this class of games. This is nice, because they are a lot easier to encode than histories (see the position hashing section). However, we can also take advantage of much more subtle aspects of these symbols, and use the freedom we have when definining them to our benefit.\nSymbolic Reduction # One of the clearest mappings we could establish from histories to some symbolic representation is to simply write down strings of actions. For example, a position of Tic-Tac-Toe could be:\n[top left X][middle middle O][middle left X] However, this is equivalent to the position:\n[middle left X][middle middle O][top left X] Here, we can apply our first trick; we will choose symbols that reflect the fact that these two histories are the same. This is easy, since the board already accomplishes this:\nX | | - + - + - X | O | - + - + - | | In making this change, we have already cut down the number of symbols we will ever see by a significant amount. But observe the following position, which is symmetric to the one above:\n| | - + - + - X | O | - + - + - X | | We can define a new function $g : P \\to P\u0026rsquo;$ that takes a symbol from the set of possible board configurations and returns one of its \u0026ldquo;symmetries,\u0026rdquo; in such a way that\n$$ g(p) = g(q) \\iff p \\text{ is symmetric to } q. $$With the understanding that $f : H \\to P$ maps game histories to game boards, we can compose $g \\circ f$ to obtain a new function that both preserves the game\u0026rsquo;s structure and reduces the amount of symbols (and therefore positions) necessary to analyze it even further.\nIt is okay if you do not understand this technique. It takes time to internalize, and you will not need it for this part. Interpret it as \u0026ldquo;treat all symmetries of the same board as one position.\u0026rdquo;\nTechniques like the ones above, which reduce the amount of positions in a game in a way that retains information about its history structure through a wise choice of symbolic mappings, collectively form what is known as \u0026ldquo;game abstraction.\u0026rdquo;\nPositional Solvers # To reap the benefits of a reduced position count, we must ensure that we only explore the reduced symbol space. The most general approach to doing this is to interpret the structure of this space as a graph, where symbols are nodes connected by actions. This is because some games that exhibit possibly infinite play can be reduced to finite-position graphs that include cycles.\nIn cases where infinite play is impossible (regardless of strategy), the \u0026ldquo;game graph\u0026rdquo; (which is to symbols what \u0026ldquo;game tree\u0026rdquo; is to histories) is a DAG. In such cases, a naive solving algorithm such as the one shown in the naive solvers subsection can be adapted to only explore the space of symbols via memoization. An example of such a game is Tic-Tac-Toe. This would have a form similar to this:\nfunction solve(position, seen) if position has been seen return value of position if position is terminal mark position as seen store position\u0026#39;s value return value of position else opponent = worst_value( solve(result of taking action from position) for action in possible actions from position ) value = opposite_value(opponent) mark position as seen store position\u0026#39;s value return value Deliverable # Modify or replace your solver from Part 1 to be able to solve 100-to-0-by-1-or-2 instantly (if it can\u0026rsquo;t already). This will require that you implement some of the ideas in the positional solvers section. You should not need to change any of the code in your zero_by implementation.\nOnce that works, create a new Game implementation for Tic-Tac-Toe using its \u0026ldquo;physical\u0026rdquo; board configurations as position symbols. You do not need to reduce the amount of boards in any way. Writing tests will be very helpful.\nFinally, format and print the number of winning, losing, and tying positions under the above symbolic representation of Tic-Tac-Toe when queried. See the checks section for specifics.\nDo not write a separate solver for Tic-Tac-Toe; use the same one for both games.\nThis means that you will somehow have to turn your \u0026ldquo;symbolic representation\u0026rdquo; of a tic-tac-toe board (e.g., [['x', 'o', 'x'], ...]) into an int and vice versa. This is known as position hashing and unhashing, and we have included an appendix with an introduction to the topic.\nThis can be a complicated matter, so to help you do this, we have written a Python class that does this for you (but assumes a board encoding). Feel free to use it if your solution is in Python. Otherwise, you will need to write your own.\nChecks # The following commands will be ran from your submission\u0026rsquo;s top-level directory verbatim. We will expect to see the output shown below each of them in STDOUT. There will be no input provided through STDIN.\nYou will need to read the ITEMIZED environment variable to determine whether or not to print a per-position breakdown of values like you did for Part 1. This is because it would be messy to print all position-to-value mappings in Tic-Tac-Toe.\n100-to-0-by-1-or-2 # Command:\nITEMIZED=1 make run ARGS=\u0026#34;zero_by 100 1 2\u0026#34; Output:\n100: TODO 99: TODO \u0026lt;CUT 98 LINES FOR BREVITY\u0026gt; 1: WIN 0: LOSE WIN: TODO TIE: TODO LOSE: TODO TOTAL: 101 Tic-Tac-Toe # Command:\nITEMIZED=0 make run ARGS=\u0026#34;tic_tac_toe\u0026#34; Output:\nWIN: 2836 TIE: 1068 LOSE: 1574 TOTAL: 5478 Appendix # While techniques in game abstraction help us drastically reduce the number of positions we must traverse when doing search, there is still the problem of encoding their symbols in a computer program. We will take a brief overview of how this is done by turning position symbols into numbers, and will introduce some systems problems related to this.\nPosition Encoding # Remember the game interface from Part 1. What is the concrete type Position? When creating systems that will be used to solve many different games, we make sure that all games agree on a single position encoding data type, which is usually a 64-bit integer. This is in contrast to making it, for example, a list of integers.\nThe reason we make this seemingly arbitrary choice is because having a fixed-size datatype means that a lot of the machine code needed to hande it can be streamlined at compilation time. We choose an integer datatype specifically because bitwise operations on integers are usually available, making it easy to do bit-level symbol encodings.\nIt is not difficult to express a position symbol for an abstract strategy game in most modern programming languages because the symbols themselves are expressed in terms of fundamental mathematical objects (e.g., grids, sets, etc.), which enjoy ample library provisions. But when given such a representation, how do we turn it into a 64-bit integer?\nHashing and Unhashing # There is no single answer for this, but without adding any constraints, it is also not a very hard problem. To inspire you, here is one way you could do it for Tic-Tac-Toe in a 32-bit integer:\nAB CD EF GH IJ KL MN OP QR 00 00 00 00 00 00 00 Here, each letter is a bit. Each pair of letters stands for a single number (e.g., 11 is 3 in binary). There are 9 pairs of letters, one for each square in the Tic-Tac-Toe board. When there is a 00, that will mean there is nothing in that square. When there is a 01, there is an X. 10 will be an O. Just like that, we have created a what is known as a hash function for Tic-Tac-Toe positions.\nA function that carries out the inverse process (in this example, turning a 32-bit integer into our representation of a Tic-Tac-Toe position) is known as an unhashing function. When writing a game-solving system, it is usually necessary to implement both to enable back-and-forth communication between solving algorithms and Game implementations.\nHigh-efficiency Game implementations operate on 64-bit integers directly as position representations, eliminating the need for hashing and unhashing. However, this is very unergonomic from a programming standpoint.\nIssues At Scale # However, there are very real constraints associated with most game-solving systems. Most of them are associated with storing very large datasets. In general, there are two options when it comes to storing a mapping of positions to any kind of value: Storing hashes or not.\nYou can store a mapping of key-value pairs (with position hashes as keys) by using hash values to index into an array of values. However, this relies on the density of the hash function being relatively high (while staying collision-free), which is generally very difficult to achieve. For very sparse hashes, you end up with a mostly empty array that wastes space. This is what would happen if you used the hash function described above.\nIf you do store hashes, you will pay an upfront space cost of the hash size for every value you wish to store. This may seem like a small overhead, but when you consider that the values being stored are usually no more than a few bits in length, it is hard to justify using up to 90% of your space just to store hashes (which are usually 64 bits in length). Furthermore, it becomes slower to query the mapping, as you no longer have the benefit of constant-time array lookups.\nThese are only problems for bigger games. You do not need to worry about any of this for now.\n"},{"id":5,"href":"/main/assignments/specification/","title":"Specification","section":"Course Assignments","content":" Specification # Due date: TODO\nWarning: This page is under construction.\n"},{"id":6,"href":"/main/assignments/presentation/","title":"Presentation","section":"Course Assignments","content":" Presentation # Due date: TODO\nWarning: This page is under construction.\n"},{"id":7,"href":"/main/about/group/","title":"About the Group","section":"Information","content":" About GamesCrafters # Warning: This page is under construction.\n"},{"id":8,"href":"/main/people/organizers/","title":"Course Organizers","section":"People","content":" Course Organizers # Warning: This page is under construction.\n"},{"id":9,"href":"/main/links/uni/","title":"GamesmanUni","section":"Links","content":"\n"},{"id":10,"href":"/main/people/alumni/","title":"Group Alumni","section":"People","content":" GamesCrafters Alumni # Warning: This page is under construction.\n"},{"id":11,"href":"/main/about/misc/","title":"Miscellaneous","section":"Information","content":" Extra Information # Warning: This page is under construction.\n"},{"id":12,"href":"/main/people/groups/","title":"Past Groups","section":"People","content":" GamesCrafters Groups # Warning: This page is under construction.\n"}]